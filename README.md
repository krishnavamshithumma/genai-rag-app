# ğŸ“„ Intelligent Manual Assistant â€” GenAI Q\&A System

## ğŸ” Problem Statement

Businesses produce large, dense operational manuals that employees and customers often struggle to navigate. This leads to:

* Wasted time searching for specific information
* Increased support overhead
* Low engagement with documentation

## ğŸ’¡ Solution

This project implements an **end-to-end AI-powered Question Answering system** that enables users to:

* Upload any business manual (PDF)
* Ask natural language questions
* Instantly get accurate, sourced answers
* View prior Q\&A context (chat-style)

Built using **LangChain**, **FAISS**, **OpenAI LLMs**, and **Streamlit**, this app enhances manual usability, reduces repetitive queries, and improves information accessibility.

## ğŸš€ Features

* ğŸ” **Conversational memory**: Caches and recalls prior questions
* ğŸ“š **PDF support**: Upload long manuals, no preprocessing needed
* ğŸ” **Semantic retrieval (RAG)**: Matches relevant sections before querying the LLM
* ğŸ’¬ **Chat interface**: Intuitive and interactive Q\&A
* ğŸ’¾ **FAISS vector store**: Local, fast, cost-efficient search

## ğŸ“ Project Structure

```
genai_rag_app/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config.py              # Loads .env configs
â”‚   â”œâ”€â”€ loader.py              # PDF to text chunks
â”‚   â”œâ”€â”€ vector_store.py        # Embeddings + FAISS store
â”‚   â”œâ”€â”€ qa_chain.py            # Conversational chain + memory
â”‚   â””â”€â”€ ui.py                  # Streamlit logic
â”œâ”€â”€ main.py                    # App entrypoint
â”œâ”€â”€ .env                       # Stores OpenAI API key
â”œâ”€â”€ requirements.txt           # All dependencies
â””â”€â”€ README.md
```

## ğŸ”§ Setup Instructions

1. **Clone repository**

```bash
git clone https://github.com/krishnavamshithumma/genai-rag-app.git
cd genai-rag-app
```

2. **Install dependencies**

```bash
pip install -r requirements.txt
```

3. **Add your OpenAI key to `.env`**

```env
OPENAI_API_KEY=your-key-here
```

4. **Run the app**

```bash
streamlit run main.py
```

## ğŸ§  How It Works

* Loads PDF and chunks content
* Embeds chunks via `OpenAIEmbeddings`
* Stores vectors in FAISS
* Uses RAG to find best matches
* Responds via OpenAI LLM
* Remembers prior Q\&A using LangChain memory

## ğŸ¢ Business Impact

âœ… Reduces support workload
âœ… Increases document value and usability
âœ… Enhances customer and employee experience
âœ… Immediate access to trusted internal knowledge

## ğŸ” Security & Cost

* API key managed securely via `.env`
* Memory avoids repeat LLM calls â†’ cheaper

## ğŸ“ˆ Future Improvements

* Persistent FAISS DB caching
* Support for multi-file or website ingestion
* Azure OpenAI or local model support
* Fine-tuning per-business vocab

## ğŸš€ Application
![Application Screenshot](images/application.png) 

---

Built with â¤ï¸ to solve real business pain using GenAI.
